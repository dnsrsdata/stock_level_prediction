{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:05:49.018323Z",
     "end_time": "2023-04-04T21:05:49.555106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Importando os dados\n",
    "df_vendas = pd.read_csv('../data/raw/sales.csv', index_col=0)\n",
    "df_estoque_lvl = pd.read_csv('../data/raw/sensor_stock_levels.csv', index_col=0)\n",
    "df_temperatura = pd.read_csv('../data/raw/sensor_storage_temperature.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:05:49.555106Z",
     "end_time": "2023-04-04T21:05:49.672342Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tratando o timestamp\n",
    "Conforme visto na documentação, as tabelas podem ser unidas usando o timestamp, mas essa variável é medida de forma diferente nas tabelas, dificultando assim a mesclagem. Para resolver isso irei alterar o timestamp apenas para data e hora sem minutos, pois como definido no problema, os sensores realizarão medidas hora a hora.\n",
    "\n",
    "Como a transformação funcionará:\n",
    "\n",
    "06/05/2020 19:45 -> 06/05/2020 19:00\n",
    "09/04/2019 16:10 -> 09/04/2019 16:00\n",
    "19/10/2021 09:30 -> 19/10/2021 09:00"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Alterando a coluna timestamp\n",
    "df_vendas['timestamp'] = pd.to_datetime(df_vendas.timestamp.str.slice(0, 16))\n",
    "df_estoque_lvl['timestamp'] = pd.to_datetime(df_estoque_lvl.timestamp.str.slice(0, 16))\n",
    "df_temperatura['timestamp'] = pd.to_datetime(df_temperatura.timestamp.str.slice(0, 16))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:05:49.686057Z",
     "end_time": "2023-04-04T21:05:49.736505Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unindo as tabelas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(92, 11)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unindo as tabelas e verificando o shape\n",
    "df_vendas.merge(df_estoque_lvl, on = ['product_id', 'timestamp']).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:05:49.736505Z",
     "end_time": "2023-04-04T21:05:49.815123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9882488184953379"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando a perda de dados\n",
    "1 - df_vendas.merge(df_estoque_lvl, on = ['product_id', 'timestamp']).shape[0]/df_vendas.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:05:49.774836Z",
     "end_time": "2023-04-04T21:05:49.829922Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como a data e hora das vendas são diferentes das datas e hora das medições dos sensores, a união realizada pelo método **merge** está causando uma perda de cerca de 98% dos dados de vendas, o que é bastante.\n",
    "\n",
    "Para solucionar esse problema, iremos unir os datasets manualmente utilizando o id e data, onde um produto será unido ao percentual de estoque anterior ao timestamp da venda."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Criando lista vazia\n",
    "lista_prcnt_estoque = []\n",
    "\n",
    "# Criando um loop para iterar sob cada indice\n",
    "for num in range(0, df_vendas.shape[0]):\n",
    "\n",
    "    # Tentando unir os dados usando o ID e o Timestamp\n",
    "    df_filtrado = df_estoque_lvl.query(f\"timestamp == '{str(df_vendas.iloc[num, 1])}' and product_id == '{df_vendas.iloc[num, 2]}'\")\n",
    "\n",
    "    # Definindo um condicional para caso a união anterior não seja realizada\n",
    "    if df_filtrado.shape[0] == 0:\n",
    "\n",
    "       # Buscando os timestamp referentes ao ID do produto na tabela de estoque\n",
    "        timestamp_estoque = df_estoque_lvl.query(f\"product_id == '{df_vendas.iloc[num, 2]}'\").timestamp.to_list()\n",
    "\n",
    "       # Buscando os timestamp referentes ao ID do produto na tabela de vendas e adicionando a uma lista\n",
    "        timestamp_venda = df_vendas.iloc[num, 1]\n",
    "        timestamp_estoque.append(timestamp_venda)\n",
    "\n",
    "        # Ordenando as variáveis\n",
    "        timestamp_ordenado = sorted(timestamp_estoque)\n",
    "\n",
    "       # Obtendo a data anterior a da venda e salvando em uma variável\n",
    "        index_timestamp = timestamp_ordenado.index(timestamp_venda) - 1\n",
    "        timestamp_novo = timestamp_ordenado[index_timestamp]\n",
    "\n",
    "       # Buscando a pctg de estoque usando o ID e o novo Timestamp\n",
    "        df_filtrado = df_estoque_lvl.query(f\"timestamp == '{timestamp_novo}' and product_id == '{df_vendas.iloc[num, 2]}'\")\n",
    "        lvl_estoque = df_filtrado.estimated_stock_pct.values[0]\n",
    "\n",
    "        # Adicionando a uma lista\n",
    "        lista_prcnt_estoque.append(lvl_estoque)\n",
    "\n",
    "    # Juntando as tabelas normalmente caso o condicional não seja atendido\n",
    "    else:\n",
    "        lvl_estoque = df_filtrado.estimated_stock_pct.values[0]\n",
    "        lista_prcnt_estoque.append(lvl_estoque)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:05:49.808614Z",
     "end_time": "2023-04-04T21:08:15.101090Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Adicionando os valores ao dataset de vendas\n",
    "df_vendas['prcnt_stock'] = lista_prcnt_estoque"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:08:15.114019Z",
     "end_time": "2023-04-04T21:08:15.163959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         id           timestamp  temperature\n14130  d451bd29-d3d2-42a1-b228-150b5ba4d664 2022-03-01 09:00:00        -1.93\n15982  148a729c-0926-4f8b-9bda-f214d0f67b8d 2022-03-01 09:00:00         1.00\n5593   151f56ba-b488-4297-b503-f5b50fee2be7 2022-03-01 09:00:00        -2.10\n6061   d050c5f2-0ffc-49ee-b8a0-beef559f5b29 2022-03-01 09:00:00         1.85\n7495   fb02fefe-da3a-4e1d-98be-f6523bc6fac6 2022-03-01 09:00:00        -2.45\n...                                     ...                 ...          ...\n14453  4a978e83-4b25-4648-85c5-f354e015fe4d 2022-03-07 19:59:00        -2.91\n7902   36a6cdb6-b344-4bfb-ab21-4f33ffe064e0 2022-03-07 19:59:00         0.71\n18379  d502a503-33ec-49c8-97e7-792aa6ce3421 2022-03-07 19:59:00        -2.98\n12147  33313da5-9999-4aef-a595-63ad14fe9468 2022-03-07 19:59:00         0.55\n4786   4618ae06-d829-4a3c-8453-e931f3a474e4 2022-03-07 19:59:00        22.55\n\n[23890 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestamp</th>\n      <th>temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14130</th>\n      <td>d451bd29-d3d2-42a1-b228-150b5ba4d664</td>\n      <td>2022-03-01 09:00:00</td>\n      <td>-1.93</td>\n    </tr>\n    <tr>\n      <th>15982</th>\n      <td>148a729c-0926-4f8b-9bda-f214d0f67b8d</td>\n      <td>2022-03-01 09:00:00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>5593</th>\n      <td>151f56ba-b488-4297-b503-f5b50fee2be7</td>\n      <td>2022-03-01 09:00:00</td>\n      <td>-2.10</td>\n    </tr>\n    <tr>\n      <th>6061</th>\n      <td>d050c5f2-0ffc-49ee-b8a0-beef559f5b29</td>\n      <td>2022-03-01 09:00:00</td>\n      <td>1.85</td>\n    </tr>\n    <tr>\n      <th>7495</th>\n      <td>fb02fefe-da3a-4e1d-98be-f6523bc6fac6</td>\n      <td>2022-03-01 09:00:00</td>\n      <td>-2.45</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14453</th>\n      <td>4a978e83-4b25-4648-85c5-f354e015fe4d</td>\n      <td>2022-03-07 19:59:00</td>\n      <td>-2.91</td>\n    </tr>\n    <tr>\n      <th>7902</th>\n      <td>36a6cdb6-b344-4bfb-ab21-4f33ffe064e0</td>\n      <td>2022-03-07 19:59:00</td>\n      <td>0.71</td>\n    </tr>\n    <tr>\n      <th>18379</th>\n      <td>d502a503-33ec-49c8-97e7-792aa6ce3421</td>\n      <td>2022-03-07 19:59:00</td>\n      <td>-2.98</td>\n    </tr>\n    <tr>\n      <th>12147</th>\n      <td>33313da5-9999-4aef-a595-63ad14fe9468</td>\n      <td>2022-03-07 19:59:00</td>\n      <td>0.55</td>\n    </tr>\n    <tr>\n      <th>4786</th>\n      <td>4618ae06-d829-4a3c-8453-e931f3a474e4</td>\n      <td>2022-03-07 19:59:00</td>\n      <td>22.55</td>\n    </tr>\n  </tbody>\n</table>\n<p>23890 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando a próxima tabela\n",
    "df_temperatura.sort_values('timestamp')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:08:15.149184Z",
     "end_time": "2023-04-04T21:08:15.218893Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aqui a nossa abordagem será alterada, pois ao contrário da tabela de estoque, onde tínhamos valores únicos por timestamp devido a diferenciação proporcionada ID, não possuímos a mesma diferenciação aqui, onde cada timestamp possui vários valores diferentes de temperatura.\n",
    "\n",
    "Sendo assim, irei agrupar o timestamp e calcular algumas estatísticas para cada horário, como média, desvio padrão, mediana, variância, etc. É necessário valores únicos para uma união sem perda de valor entre as tabelas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Computando estatísticas e resetando o index\n",
    "df_temperatura = df_temperatura.groupby('timestamp').temperature.agg(['std', 'var', 'sem', 'mean', 'median', 'min', 'max'])\n",
    "df_temperatura = df_temperatura.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:08:15.213874Z",
     "end_time": "2023-04-04T21:08:15.409793Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Unindo as tabelas\n",
    "df_final = df_vendas.merge(df_temperatura, on = 'timestamp')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T21:09:59.723242Z",
     "end_time": "2023-04-04T21:09:59.741031Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

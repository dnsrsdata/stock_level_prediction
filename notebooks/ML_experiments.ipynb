{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Experimentação de modelos\n",
    " Nesta sessão irei realizar uma série de experimentos, combinando diferentes modelos e preprocessamentos. Para registrar tudo isso, irei utilizar o MLFlow.\n",
    "\n",
    "Aqui irei testar modelos baseados em distância e árvore, segue os esboços dos testes a serem realizados:\n",
    "\n",
    "Baseados em estatística:\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder em todas as categóricas.\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder nas categóricas nominais + Ordinal Encoder nas ordinais.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em todas as categóricas.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em nas categóricas nominais + Ordinal Encoder nas ordinais.\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder em todas as categóricas + Isolation Forest para rotular os outliers.\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder nas categóricas nominais + Ordinal Encoder nas ordinais + Isolation Forest para rotular os outliers.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em todas as categóricas + Isolation Forest para rotular os outliers.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em nas categóricas nominais + Ordinal Encoder nas ordinais + Isolation Forest para rotular os outliers.\n",
    "\n",
    "\n",
    "Baseados em árvore:\n",
    "- CatBoost Encoder nas categóricas\n",
    "- CatBoost Encoder nas categóricas + Isolation Forest para rotular os outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T17:36:57.729235Z",
     "start_time": "2023-04-09T17:36:57.708927Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "\n",
    "import category_encoders as ce\n",
    "import joblib\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Métodos para criar transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Modelos\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Ignorando as mensagens de erro\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Definindo padrão de gráfico\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IFInput(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, random_state = None):\n",
    "    \n",
    "        # Salvando o input localmente\n",
    "        self.column = column\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Calculando os quartis e o IQR\n",
    "        q1 = np.quantile(X[self.column], 0.25)\n",
    "        q3 = np.quantile(X[self.column], 0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Calculando o grau de contaminação\n",
    "        qtd_outliers = X.query(f\"{self.column} > {q3 + 1.5 * iqr}\").shape[0]\n",
    "        qtd_total_registros = X.shape[0]\n",
    "        prcnt_contamination = qtd_outliers/qtd_total_registros\n",
    "        \n",
    "        # Salvando o modelo localmente\n",
    "        self.iso_forest = IsolationForest(contamination=prcnt_contamination,\n",
    "                                          random_state=self.random_state)\n",
    "        \n",
    "        # Fitando os dados\n",
    "        self.iso_forest.fit(X[self.column].values.reshape(-1, 1))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        self.label = self.iso_forest.predict(X[self.column].values.reshape(-1, 1))\n",
    "        \n",
    "        # Adiciona os valores ao dataset\n",
    "        X['is_outlier'] = self.label\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:39:43.180683Z",
     "start_time": "2023-04-09T16:39:43.157413Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def registrarexperimento(modelos, tags, transformer, x_treino, y_treino, IF = None):\n",
    "    \"\"\"\n",
    "    Função para registrar experimentos de acordo com modelos, tags e transformadores específicos.\n",
    "    :param modelos: lista contendo os modelos a serem testados\n",
    "    :param tags: lista contendo tags de identificação para cada modelo e transformações aplicadas\n",
    "    :param transformer: transformações que serão aplicadas ao conjunto de treino\n",
    "    :param x_treino: dados contendo as variáveis dependentes\n",
    "    :param y_treino: target\n",
    "    :param IF: algorítmo para detectar outliers\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Iterando com os modelos da lista\n",
    "    for model in modelos:\n",
    "\n",
    "        # Iniciando os experimentos\n",
    "        with mlflow.start_run():\n",
    "\n",
    "            # Colocando uma tag para identificação\n",
    "            index_modelo = modelos.index(model)\n",
    "            mlflow.set_tag('modelo', tags[index_modelo])\n",
    "\n",
    "            if IF != None:\n",
    "            \n",
    "                # Criando o pipeline\n",
    "                pipe = Pipeline([('outlier_detect', IF),\n",
    "                                 ('transformer', transformer),\n",
    "                                 ('regressor', model)])\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # Criando o pipeline\n",
    "                pipe = Pipeline([('transformer', transformer),\n",
    "                                 ('regressor', model)])\n",
    "                \n",
    "            # Calculando as métricas com cross-validation\n",
    "            mae_mean = cross_val_score(pipe,\n",
    "                                        x_treino,\n",
    "                                        y_treino,\n",
    "                                        cv=5,\n",
    "                                        scoring='neg_mean_absolute_error').mean() * (-1)\n",
    "\n",
    "            mae_std = cross_val_score(pipe,\n",
    "                                        x_treino,\n",
    "                                        y_treino,\n",
    "                                        cv=5,\n",
    "                                        scoring='neg_mean_absolute_error').std() * (-1)\n",
    "\n",
    "            rmse_mean = cross_val_score(pipe,\n",
    "                                        x_treino,\n",
    "                                        y_treino,\n",
    "                                        cv=5,\n",
    "                                        scoring='neg_root_mean_squared_error').mean() * (-1)\n",
    "\n",
    "            rmse_std = cross_val_score(pipe,\n",
    "                                        x_treino,\n",
    "                                        y_treino,\n",
    "                                        cv=5,\n",
    "                                        scoring='neg_root_mean_squared_error').std() * (-1)\n",
    "\n",
    "            # Salvando as métricas\n",
    "            mlflow.log_metric('mae_mean', mae_mean)\n",
    "            mlflow.log_metric('mae_std', mae_std)\n",
    "            mlflow.log_metric('rmse_mean', rmse_mean)\n",
    "            mlflow.log_metric('rmse_std', rmse_std)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:16:39.371903Z",
     "start_time": "2023-04-09T16:16:39.307786Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importando os dados\n",
    "dados = pd.read_csv('../data/processed/dados_para_treino.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:16:41.224971Z",
     "start_time": "2023-04-09T16:16:41.133330Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checando a tabela\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Alterando o tipo das colunas\n",
    "Antes de iniciar os experimentos irei realizar uma pequena mudança nos tipos das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:25:40.848185Z",
     "start_time": "2023-04-09T16:25:40.814133Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alterando o tipo de dado\n",
    "dados['day_of_week'] = dados.day_of_week.astype('object')\n",
    "dados['customer_type'] = dados.customer_type.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Buscando o melhor algorítmo\n",
    "\n",
    "A partir daqui iniciarei os experimentos. Nesta etapa **NÃO** irei alterar os parâmetros, onde o melhor modelo irá receber tunning em outra rodada de experimentos.\n",
    "\n",
    "Iniciarei os experimentos com os algoritmos **baseados em distância**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:16:51.580121Z",
     "start_time": "2023-04-09T16:16:51.547271Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define o local para salvar os exoerimentos\n",
    "mlflow.set_tracking_uri('../mlruns')\n",
    "\n",
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando modelos')\n",
    "\n",
    "# Dividindo os dados em variáveis dependentes e independentes\n",
    "x = dados.drop(columns='lvl_estoque_to_predict')\n",
    "y = dados.lvl_estoque_to_predict\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=14)\n",
    "\n",
    "# Dividindo os dados em dev e teste\n",
    "x_dev, x_teste, y_dev, y_teste = train_test_split(x_teste,\n",
    "                                                  y_teste,\n",
    "                                                  test_size=0.50,\n",
    "                                                  random_state=14)\n",
    "\n",
    "# Instanciando os modelos\n",
    "linear_reg = LinearRegression()\n",
    "lasso = Lasso(random_state=47)\n",
    "ridge = Ridge(random_state=47)\n",
    "elastic_nt = ElasticNet(random_state=47)\n",
    "reg_estocastico = SGDRegressor(random_state=47)\n",
    "\n",
    "# Criando listas com os modelo\n",
    "modelos = [linear_reg, lasso, ridge, elastic_nt, reg_estocastico]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Standard Scaler em todas as variáveis numéricas + One Hot Encoder em todas as categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:25:59.293272Z",
     "start_time": "2023-04-09T16:25:59.278102Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, numericas),\n",
    "                                              ('encoder', ohe, categoricas)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_OHE', 'Lasso_SC_OHE', 'Ridge_SC_OHE', 'Elastic_Net_SC_OHE', 'Reg_Estocástico_SC_OHE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:36:25.537536Z",
     "start_time": "2023-04-09T16:36:20.682579Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Standard Scaler em todas as variáveis numéricas + One Hot Encoder nas categóricas nominais + Ordinal Encoder nas ordinais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:30:10.081737Z",
     "start_time": "2023-04-09T16:30:10.061556Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "oe = ce.ordinal.OrdinalEncoder()\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "categoricas = x_treino.select_dtypes('object').columns\n",
    "ordinais = x_treino.select_dtypes('category').columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, numericas),\n",
    "                                              ('encoder_nominal', ohe, categoricas),\n",
    "                                              ('encoder_ordinal', oe, ordinais)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_OHE_OE', 'Lasso_SC_OHE_OE', 'Ridge_SC_OHE_OE', 'Elastic_Net_SC_OHE_OE', 'Reg_Estocástico_SC_OHE_OE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:30:18.075649Z",
     "start_time": "2023-04-09T16:30:13.001729Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em todas as categóricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:54:08.156376Z",
     "start_time": "2023-04-09T16:54:08.096637Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando uma lista vazia\n",
    "col_com_outlier = []\n",
    "\n",
    "# Buscando todas as variáveis numéricas\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "\n",
    "# Iterando sobre as colunas numéricas\n",
    "for col in numericas:\n",
    "\n",
    "    # Calculando os quartis e o IQR\n",
    "    q1 = np.quantile(dados[col], 0.25)\n",
    "    q3 = np.quantile(dados[col], 0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    #Separando os dados sem e com outliers\n",
    "    if dados.query(f\"{col} > {q3 + 1.5 * iqr}\").shape[0] > 0:\n",
    "        col_com_outlier.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:58:46.442752Z",
     "start_time": "2023-04-09T16:58:46.395186Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "rs = RobustScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "num_com_outliers = col_com_outlier\n",
    "num_sem_outliers = [col for col in x_treino.select_dtypes(['int', 'float']).columns if col not in col_com_outlier]\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, num_sem_outliers),\n",
    "                                              ('scaler_outliers', rs, num_com_outliers),\n",
    "                                              ('encoder_nominal', ohe, categoricas)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_RS_OHE', 'Lasso_SC_RS_OHE', 'Ridge_SC_RS_OHE', 'Elastic_Net_SC_RS_OHE', 'Reg_Estocástico_SC_RS_OHE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em nas categóricas nominais + Ordinal Encoder nas ordinais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando uma lista vazia\n",
    "col_com_outlier = []\n",
    "\n",
    "# Buscando todas as variáveis numéricas\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "\n",
    "# Iterando sobre as colunas numéricas\n",
    "for col in numericas:\n",
    "\n",
    "    # Calculando os quartis e o IQR\n",
    "    q1 = np.quantile(dados[col], 0.25)\n",
    "    q3 = np.quantile(dados[col], 0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    #Separando os dados sem e com outliers\n",
    "    if dados.query(f\"{col} > {q3 + 1.5 * iqr}\").shape[0] > 0:\n",
    "        col_com_outlier.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "rs = RobustScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "oe = ce.ordinal.OrdinalEncoder()\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "num_com_outliers = col_com_outlier\n",
    "num_sem_outliers = [col for col in x_treino.select_dtypes(['int', 'float']).columns if col not in col_com_outlier]\n",
    "categoricas = x_treino.select_dtypes('object').columns\n",
    "ordinais = x_treino.select_dtypes('category').columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, num_sem_outliers),\n",
    "                                              ('scaler_outliers', rs, num_com_outliers),\n",
    "                                              ('encoder_nominal', ohe, categoricas),\n",
    "                                              ('encoder_ordinal', oe, ordinais)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_RS_OHE_OE', 'Lasso_SC_RS_OHE_OE', 'Ridge_SC_RS_OHE_OE', 'Elastic_Net_SC_RS_OHE_OE', 'Reg_Estocástico_SC_RS_OHE_OE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Standard Scaler em todas as variáveis numéricas + One Hot Encoder em todas as categóricas + Isolation Forest para rotular os outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "outdetector = IFInput('total', random_state=47)\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).drop(columns='total').columns\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "outlier = ['total']\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('encoder', ohe, categoricas),\n",
    "                                              ('scaler', sc, numericas)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_OHE_IF', 'Lasso_SC_OHE_IF', 'Ridge_SC_OHE_IF', 'Elastic_Net_SC_OHE_IF', 'Reg_Estocástico_SC_OHE_IF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino, outdetector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler em todas as variáveis numéricas + One Hot Encoder nas categóricas nominais + Ordinal Encoder nas ordinais + Isolation Forest para rotular os outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "oe = ce.ordinal.OrdinalEncoder()\n",
    "outdetector = IFInput('total', random_state=47)\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "categoricas = x_treino.select_dtypes('object').columns\n",
    "ordinais = x_treino.select_dtypes('category').columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, numericas),\n",
    "                                              ('encoder_nominal', ohe, categoricas),\n",
    "                                              ('encoder_ordinal', oe, ordinais)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_OHE_OE_IF', 'Lasso_SC_OHE_OE_IF', 'Ridge_SC_OHE_OE_IF', 'Elastic_Net_SC_OHE_OE_IF', 'Reg_Estocástico_SC_OHE_OE_IF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino, outdetector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em todas as categóricas + Isolation Forest para rotular os outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista vazia\n",
    "col_com_outlier = []\n",
    "\n",
    "# Buscando todas as variáveis numéricas\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "\n",
    "# Iterando sobre as colunas numéricas\n",
    "for col in numericas:\n",
    "\n",
    "    # Calculando os quartis e o IQR\n",
    "    q1 = np.quantile(dados[col], 0.25)\n",
    "    q3 = np.quantile(dados[col], 0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    #Separando os dados sem e com outliers\n",
    "    if dados.query(f\"{col} > {q3 + 1.5 * iqr}\").shape[0] > 0:\n",
    "        col_com_outlier.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "rs = RobustScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "outdetector = IFInput('total', random_state=47)\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "num_com_outliers = col_com_outlier\n",
    "num_sem_outliers = [col for col in x_treino.select_dtypes(['int', 'float']).columns if col not in col_com_outlier]\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, num_sem_outliers),\n",
    "                                              ('scaler_outliers', rs, num_com_outliers),\n",
    "                                              ('encoder_nominal', ohe, categoricas)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_RS_OHE_IF', 'Lasso_SC_RS_OHE_IF', 'Ridge_SC_RS_OHE_IF', 'Elastic_Net_SC_RS_OHE_IF', 'Reg_Estocástico_SC_RS_OHE_IF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino, outdetector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em nas categóricas nominais + Ordinal Encoder nas ordinais + Isolation Forest para rotular os outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista vazia\n",
    "col_com_outlier = []\n",
    "\n",
    "# Buscando todas as variáveis numéricas\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "\n",
    "# Iterando sobre as colunas numéricas\n",
    "for col in numericas:\n",
    "\n",
    "    # Calculando os quartis e o IQR\n",
    "    q1 = np.quantile(dados[col], 0.25)\n",
    "    q3 = np.quantile(dados[col], 0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    #Separando os dados sem e com outliers\n",
    "    if dados.query(f\"{col} > {q3 + 1.5 * iqr}\").shape[0] > 0:\n",
    "        col_com_outlier.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "rs = RobustScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "oe = ce.ordinal.OrdinalEncoder()\n",
    "outdetector = IFInput('total', random_state=47)\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "num_com_outliers = col_com_outlier\n",
    "num_sem_outliers = [col for col in x_treino.select_dtypes(['int', 'float']).columns if col not in col_com_outlier]\n",
    "categoricas = x_treino.select_dtypes('object').columns\n",
    "ordinais = x_treino.select_dtypes('category').columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, num_sem_outliers),\n",
    "                                              ('scaler_outliers', rs, num_com_outliers),\n",
    "                                              ('encoder_nominal', ohe, categoricas),\n",
    "                                              ('encoder_ordinal', oe, ordinais)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['Reg_Linear_SC_RS_OHE_OE_IF', 'Lasso_SC_RS_OHE_OE_IF', 'Ridge_SC_RS_OHE_OE_IF', 'Elastic_Net_SC_RS_OHE_OE_IF', 'Reg_Estocástico_SC_RS_OHE_OE_IF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino, outdetector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir desse ponto iniciarei os experimentos com algoritmos **baseados em árvore**. Lembrando que algorítmos desse tipo não necessitam de um scaler, pois não são sensíveis as escalas dos dados. Além disso, aplicar One Hot Encoder não é recomendado, pois essa técnica irá aumentar a cardinalidade dos dados, prejudicando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os modelos\n",
    "tree_reg = DecisionTreeRegressor(random_state=47)\n",
    "xtree_reg = ExtraTreeRegressor(random_state=47)\n",
    "rf_reg = RandomForestRegressor(random_state=47)\n",
    "gb_reg = GradientBoostingRegressor(random_state=47)\n",
    "xgb_reg = XGBRegressor(random_state=47)\n",
    "\n",
    "# Criando listas com os modelo\n",
    "modelos = [tree_reg, xtree_reg, rf_reg, gb_reg, xgb_reg]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost Encoder nas categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "cbenc = ce.CatBoostEncoder()\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('encoder', cbenc, categoricas)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['DTree_reg_CtbEnc', 'XTree_reg_CtbEnc', 'RDF_reg_CtbEnc', 'GB_reg_CtbEnc', 'XGb_reg__CtbEnc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost Encoder nas categóricas + Isolation Forest para rotular os outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "outdetector = IFInput('total', random_state=47)\n",
    "cbenc = ce.CatBoostEncoder()\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('encoder', cbenc, categoricas)])\n",
    "\n",
    "# Criando lista com as tags para identificar modelo e preprocessamento usado\n",
    "tags = ['DTree_reg_CtbEnc', 'XTree_reg_CtbEnc', 'RDF_reg_CtbEnc', 'GB_reg_CtbEnc', 'XGb_reg__CtbEnc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os experimentos\n",
    "registrarexperimento(modelos, tags, transformer, x_treino, y_treino, outdetector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão da primeira rodada de experimentos\n",
    "Nesta fase, é possível digitar ```mlflow ui ``` no terminal e verificar o resultado dos experimentos pela interfacxe gráfica do MLFlow. Embora seja possível, irei buscar os resultados e salva-los em um Dataframe.\n",
    "\n",
    "Após isso, irei ordenar os resultados pelo valor médio do **MAE**, **RMSE** e **tempo de treinamento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em uma variável \n",
    "resultados_experimentos = mlflow.search_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o tempo necessário de treinamento\n",
    "resultados_experimentos['tempo'] = resultados_experimentos.end_time - resultados_experimentos.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando o resultado e criando uma lista com colunas de interesse\n",
    "resultados_ordenados = resultados_experimentos.sort_values(['metrics.mae_mean', 'metrics.rmse_mean', 'tempo'])\n",
    "cols_interesse = ['metrics.rmse_mean', 'metrics.mae_mean', 'metrics.mae_std', 'metrics.rmse_std', 'tags.modelo', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o resultado\n",
    "resultados_ordenados.to_csv('../metrics/experiments/resultados.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando o resultado\n",
    "resultados_ordenados.loc[:, cols_interesse]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E temos o nosso modelo campeão: Ridge com Standard Scaler nas numéricas e One Hot Encoding nas categóricas. Apesar de métricas iguais entre os experimentos com o algorítmo desse tipo, o que ficou em primeiro lugar possui o menor tempo de treinamento, motivando a decisão de declara-lo o melhor.\n",
    "\n",
    "Perceba que as métricas MAE e RMSE estão próximas e o desvio padrão entre as folders do Cross Validation está bem baixa, indicando que as previsões estão constantes, sem aquelas previsões \"outliers\" que destoam das outras que o modelo realizou."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning\n",
    "Agora irei retreinar o modelo com os dados de **treino** e usar o conjunto de **dev** para buscar os melhores parâmetros. Primeiro irei criar algumas combinações manualmente, salvando o **MAE** e **RMSE**. Após isso, irei usar a interface gráfica do MLFlow e verificar qual tipo de combinação está levando o modelo a um melhor desempenho, criando um pequeno GridSearch logo depois, usando parâmetros que façam sentido e não aleatórios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Tunning melhor modelo')\n",
    "\n",
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, numericas),\n",
    "                                              ('encoder', ohe, categoricas)])\n",
    "\n",
    "\n",
    "# Criando combinações para os parâmetros alpha e n_iter\n",
    "parametros = [[7500, 100, 47],\n",
    "              [7500, 500, 47],\n",
    "              [7500, 1000, 47],\n",
    "              [7500, 3000, 47],\n",
    "              [7500, 6000, 47],\n",
    "              [7500, 12000, 47],\n",
    "              [3000, 100, 47],\n",
    "              [3000, 500, 47],\n",
    "              [3000, 1000, 47],\n",
    "              [3000, 3000, 47],\n",
    "              [3000, 6000, 47],\n",
    "              [3000, 12000, 47],\n",
    "              [1280, 100, 47],\n",
    "              [1280, 500, 47],\n",
    "              [1280, 1000, 47],\n",
    "              [1280, 3000, 47],\n",
    "              [1280, 6000, 47],\n",
    "              [1280, 12000, 47],\n",
    "              [640, 100, 47],\n",
    "              [640, 500, 47],\n",
    "              [640, 1000, 47],\n",
    "              [640, 3000, 47],\n",
    "              [640, 6000, 47],\n",
    "              [640, 12000, 47],\n",
    "              [320, 100, 47],\n",
    "              [320, 500, 47],\n",
    "              [320, 1000, 47],\n",
    "              [320, 3000, 47],\n",
    "              [320, 6000, 47],\n",
    "              [320, 12000, 47],\n",
    "              [160, 100, 47],\n",
    "              [160, 500, 47],\n",
    "              [160, 1000, 47],\n",
    "              [160, 3000, 47],\n",
    "              [160, 6000, 47],\n",
    "              [160, 12000, 47],\n",
    "              [80, 100, 47],\n",
    "              [80, 500, 47],\n",
    "              [80, 1000, 47],\n",
    "              [80, 3000, 47],\n",
    "              [80, 6000, 47],\n",
    "              [80, 12000, 47],\n",
    "              [40, 100, 47],\n",
    "              [40, 500, 47],\n",
    "              [40, 1000, 47],\n",
    "              [40, 3000, 47],\n",
    "              [40, 6000, 47],\n",
    "              [40, 12000, 47],\n",
    "              [25, 100, 47],\n",
    "              [25, 500, 47],\n",
    "              [25, 1000, 47],\n",
    "              [25, 3000, 47],\n",
    "              [25, 6000, 47],\n",
    "              [25, 12000, 47],\n",
    "              [10, 100, 47],\n",
    "              [10, 500, 47],\n",
    "              [10, 1000, 47],\n",
    "              [10, 3000, 47],\n",
    "              [10, 6000, 47],\n",
    "              [10, 12000, 47],\n",
    "              [5, 100, 47],\n",
    "              [5, 500, 47],\n",
    "              [5, 1000, 47],\n",
    "              [5, 3000, 47],\n",
    "              [5, 6000, 47],\n",
    "              [5, 12000, 47],\n",
    "              [1, 100, 47],\n",
    "              [1, 500, 47],\n",
    "              [1, 1000, 47],\n",
    "              [1, 3000, 47],\n",
    "              [1, 6000, 47],\n",
    "              [1, 12000, 47],\n",
    "              [0.1, 100, 47],\n",
    "              [0.1, 500, 47],\n",
    "              [0.1, 1000, 47],\n",
    "              [0.1, 3000, 47],\n",
    "              [0.1, 6000, 47],\n",
    "              [0.1, 12000, 47],\n",
    "              [0.01, 100, 47],\n",
    "              [0.01, 500, 47],\n",
    "              [0.01, 1000, 47],\n",
    "              [0.01, 3000, 47],\n",
    "              [0.01, 6000, 47],\n",
    "              [0.01, 12000, 47],\n",
    "              [0.001, 100, 47],\n",
    "              [0.001, 500, 47],\n",
    "              [0.001, 1000, 47],\n",
    "              [0.001, 3000, 47],\n",
    "              [0.001, 6000, 47],\n",
    "              [0.001, 12000, 47],\n",
    "              [0.0001, 100, 47],\n",
    "              [0.0001, 500, 47],\n",
    "              [0.0001, 1000, 47],\n",
    "              [0.0001, 3000, 47],\n",
    "              [0.0001, 6000, 47],\n",
    "              [0.0001, 12000, 47]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um loop para iniciar os experimentos\n",
    "for num in range(len(parametros)):\n",
    "   \n",
    "   # Buscando os parâmetros\n",
    "   alpha = parametros[num][0]\n",
    "   num_iters = parametros[num][1]\n",
    "   rs = parametros[num][2]\n",
    "   \n",
    "   # Iniciando os experimentos\n",
    "   with mlflow.start_run():\n",
    "      \n",
    "      # Criando o pipeline\n",
    "      pipe = Pipeline([('transformer', transformer),\n",
    "                       ('modelo', Ridge(alpha=alpha, max_iter=num_iters, random_state=rs))])\n",
    "      \n",
    "      # Treinando o modelo\n",
    "      pipe.fit(x_treino, y_treino)\n",
    "      \n",
    "      # Fazendo predições\n",
    "      y_dev_pred = pipe.predict(x_dev)\n",
    "      \n",
    "      # Calculando as métricas\n",
    "      mae = mean_absolute_error(y_dev, y_dev_pred)\n",
    "      rmse = mean_squared_error(y_dev, y_dev_pred, squared=False)\n",
    "    \n",
    "      # Salvando as métricas e os parâmetros\n",
    "      mlflow.log_metric('mae', mae)\n",
    "      mlflow.log_metric('rmse', rmse)\n",
    "      mlflow.log_param('alpha', alpha)\n",
    "      mlflow.log_param('max_iter', num_iters)\n",
    "      mlflow.log_param('random_state', rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em uma variável \n",
    "resultados_experimentos = mlflow.search_runs()\n",
    "\n",
    "# Salvando o resultado\n",
    "resultados_experimentos.to_csv('../metrics/experiments_tunning/resultados.csv') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao final dos experimentos, temos o seguinte gráfico:\n",
    "\n",
    "![metrics](../images/plots/metricas.png)\n",
    "\n",
    "Ao início parece um pouco confuso, mas analisando mais de perto, podemos tirar insights interessantes.\n",
    "\n",
    "Vejamos como o modelo que teve os melhores resultados se saiu:\n",
    "\n",
    "![metrics_best](../images/plots/melhor_metrica.png)\n",
    "\n",
    "Vamos aos insights:\n",
    "- Embora não apareça no gráfico, o valor de **alpha** é de 640.\n",
    "- Independente do valor do parâmetro **max_iters**, o resultado é o mesmo nos 6 modelos treinados com o **alpha** de 640.\n",
    "\n",
    "Vale lembrar que termos valores abaixo e acima de 640 que foram testados, agora vamos observar o segundo melhor modelo para obtermos mais insights em um range de busca.\n",
    "\n",
    "![metrics_second_best](../images/plots/segunda_melhor_metrica.png)\n",
    "Vamos aos insights:\n",
    "- Embora não apareça no gráfico, o valor de **alpha** é de 1280.\n",
    "- Independente do valor do parâmetro **max_iters**, o resultado é o mesmo nos 6 modelos treinados com o **alpha** de 1280.\n",
    "\n",
    "**Conclusão:** \n",
    "- Os melhores resultados estão com um **alpha** de 640 e 1280, alphas inferiores a 640 e superiores a 1280 foram testados e apresentaram resultados piores. \n",
    "- O numéro máximo de iterações não afeta o resultado.\n",
    "\n",
    "Agora, uma busca com GridSearch será realizada, com valores entre 640 e 1280 no **alpha** apenas, pois os outros parâmetros não mostraram alterar o resultado do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, numericas),\n",
    "                                              ('encoder', ohe, categoricas)])\n",
    "\n",
    "# Criando o pipeline\n",
    "pipe = Pipeline([('transformer', transformer),\n",
    "                ('modelo', Ridge(random_state=47))])\n",
    "\n",
    "# Definindo os parâmetros a serem testados\n",
    "params = {'modelo__alpha':list(range(640, 1281, 5))}\n",
    "\n",
    "# Buscando o melhor modelo\n",
    "gs_ridge = GridSearchCV(pipe, params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "gs_ridge.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os melhores parâmetros\n",
    "gs_ridge.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aqui vemos que com validação cruzada, 1280 de alpha conseguiu superar o alpha de 640 que tinha se saído melhor nos experimentos. Note que a diferença entre eles era muito baixa, portanto, seguirei com o resultado de 1280 com validação cruzada. Finalmente vamos utilizar o nosso modelo do GridSearch nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "categoricas = x_treino.select_dtypes(['object', 'category']).columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, numericas),\n",
    "                                              ('encoder', ohe, categoricas)])\n",
    "\n",
    "# Criando o pipeline\n",
    "pipe = Pipeline([('transformer', transformer),\n",
    "                ('modelo', Ridge(alpha = 1280, random_state=47))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "pipe.fit(x_treino, y_treino)\n",
    "\n",
    "# Realizando previsões\n",
    "y_pred = pipe.predict(x_teste)\n",
    "\n",
    "# Medindo as métricas\n",
    "mae = mean_absolute_error(y_pred, y_teste)\n",
    "rmse = mean_squared_error(y_pred, y_teste, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando as métricas\n",
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previsões estão semelhantes as vistas nos experimentos, então temos um bom fit aqui. Além disso, os valores de MAE e RMSE estão próximos, indicando que previsões anômalas não estão sendo realizadas pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo\n",
    "joblib.dump(pipe, '../models/pipeline.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando resultados\n",
    "Nesta sessão irei comparar o resultado entre as predições do modelo e ver se estão consistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotandoos gráficos\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.suptitle('Distribuição de valores entre teste e predições')\n",
    "sns.violinplot(list(y_teste), ax=axes[0])\n",
    "axes[0].set_title('y_teste')\n",
    "sns.violinplot(y_pred, ax=axes[1])\n",
    "axes[1].set_title('y_pred')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predições estão bem concentradas entre 0.48 e 0.52, enquanto os dados reais variam bastante. E isso é um problema, pois demonstra que o modelo não conseguiu aprender tão bem assim.\n",
    "\n",
    "Neste caso, precisaríamos de mais dados para poder produzir uma solução mais eficiente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

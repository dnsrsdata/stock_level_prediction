{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Experimentação de modelos\n",
    " Nesta sessão irei realizar uma série de experimentos, combinando diferentes modelos e preprocessamentos. Para registrar tudo isso, irei utilizar o MLFlow.\n",
    "\n",
    "Aqui irei testar modelos baseados em distância e árvore, segue os esboços dos testes a serem realizados:\n",
    "\n",
    "Baseados em distância:\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder em todas as categóricas.\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder nas categóricas nominais + Ordinal Encoder nas ordinais.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em todas as categóricas.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em nas categóricas nominais + Ordinal Encoder nas ordinais.\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder em todas as categóricas + Isolation Forest para rotular os outliers.\n",
    "- Standard Scaler em todas as variáveis numéricas + One Hot Encoder nas categóricas nominais + Ordinal Encoder nas ordinais + Isolation Forest para rotular os outliers.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em todas as categóricas + Isolation Forest para rotular os outliers.\n",
    "- Standard Scaler nas variáveis numéricas sem outliers + Robust Scaler nas variáveis com outliers + One Hot Encoder em nas categóricas nominais + Ordinal Encoder nas ordinais + Isolation Forest para rotular os outliers.\n",
    "\n",
    "\n",
    "Baseados em árvore:\n",
    "- Diferentes tipos de encoders da biblioteca **category encoders**  para as categóricas\n",
    "- Diferentes tipos de encoders da biblioteca **category encoders**  para as categóricas + Isolation Forest para rotular os outliers.\n",
    "Geral:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T17:37:54.431970Z",
     "end_time": "2023-04-06T17:37:54.439076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Importando os dados\n",
    "dados = pd.read_csv('../data/interim/dados_para_treino.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T17:28:55.463367Z",
     "end_time": "2023-04-06T17:28:55.516982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "             category customer_type  unit_price  quantity  total payment_type  \\\n0               fruit          gold        3.99         2   7.98     e-wallet   \n1               fruit       premium        1.49         1   1.49  credit card   \n2               fruit    non-member        4.49         4  17.96  credit card   \n3  refrigerated items          gold        5.99         1   5.99  credit card   \n4        canned foods          gold        2.49         1   2.49     e-wallet   \n\n   prcnt_stock       std      var       sem  mean  median   min   max  \\\n0         0.23  2.161724  4.67305  0.966752 -1.05   -2.24 -2.89  1.67   \n1         0.54  2.161724  4.67305  0.966752 -1.05   -2.24 -2.89  1.67   \n2         0.71  2.161724  4.67305  0.966752 -1.05   -2.24 -2.89  1.67   \n3         0.54  2.161724  4.67305  0.966752 -1.05   -2.24 -2.89  1.67   \n4         0.33  2.161724  4.67305  0.966752 -1.05   -2.24 -2.89  1.67   \n\n   day_of_week is_weekend  hour     turn  \n0            2         no     9  morning  \n1            2         no     9  morning  \n2            2         no     9  morning  \n3            2         no     9  morning  \n4            2         no     9  morning  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>customer_type</th>\n      <th>unit_price</th>\n      <th>quantity</th>\n      <th>total</th>\n      <th>payment_type</th>\n      <th>prcnt_stock</th>\n      <th>std</th>\n      <th>var</th>\n      <th>sem</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>min</th>\n      <th>max</th>\n      <th>day_of_week</th>\n      <th>is_weekend</th>\n      <th>hour</th>\n      <th>turn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fruit</td>\n      <td>gold</td>\n      <td>3.99</td>\n      <td>2</td>\n      <td>7.98</td>\n      <td>e-wallet</td>\n      <td>0.23</td>\n      <td>2.161724</td>\n      <td>4.67305</td>\n      <td>0.966752</td>\n      <td>-1.05</td>\n      <td>-2.24</td>\n      <td>-2.89</td>\n      <td>1.67</td>\n      <td>2</td>\n      <td>no</td>\n      <td>9</td>\n      <td>morning</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fruit</td>\n      <td>premium</td>\n      <td>1.49</td>\n      <td>1</td>\n      <td>1.49</td>\n      <td>credit card</td>\n      <td>0.54</td>\n      <td>2.161724</td>\n      <td>4.67305</td>\n      <td>0.966752</td>\n      <td>-1.05</td>\n      <td>-2.24</td>\n      <td>-2.89</td>\n      <td>1.67</td>\n      <td>2</td>\n      <td>no</td>\n      <td>9</td>\n      <td>morning</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fruit</td>\n      <td>non-member</td>\n      <td>4.49</td>\n      <td>4</td>\n      <td>17.96</td>\n      <td>credit card</td>\n      <td>0.71</td>\n      <td>2.161724</td>\n      <td>4.67305</td>\n      <td>0.966752</td>\n      <td>-1.05</td>\n      <td>-2.24</td>\n      <td>-2.89</td>\n      <td>1.67</td>\n      <td>2</td>\n      <td>no</td>\n      <td>9</td>\n      <td>morning</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>refrigerated items</td>\n      <td>gold</td>\n      <td>5.99</td>\n      <td>1</td>\n      <td>5.99</td>\n      <td>credit card</td>\n      <td>0.54</td>\n      <td>2.161724</td>\n      <td>4.67305</td>\n      <td>0.966752</td>\n      <td>-1.05</td>\n      <td>-2.24</td>\n      <td>-2.89</td>\n      <td>1.67</td>\n      <td>2</td>\n      <td>no</td>\n      <td>9</td>\n      <td>morning</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>canned foods</td>\n      <td>gold</td>\n      <td>2.49</td>\n      <td>1</td>\n      <td>2.49</td>\n      <td>e-wallet</td>\n      <td>0.33</td>\n      <td>2.161724</td>\n      <td>4.67305</td>\n      <td>0.966752</td>\n      <td>-1.05</td>\n      <td>-2.24</td>\n      <td>-2.89</td>\n      <td>1.67</td>\n      <td>2</td>\n      <td>no</td>\n      <td>9</td>\n      <td>morning</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando a tabela\n",
    "dados.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T17:28:56.940224Z",
     "end_time": "2023-04-06T17:28:56.974478Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Buscando o melhor algorítmo\n",
    "\n",
    "A partir daqui iniciarei os experimentos. Nesta etapa **NÃO** irei alterar os parâmetros, onde o melhor modelo irá receber tunning em outra rodada de experimentos.\n",
    "\n",
    "Iniciarei os experimentos com os algoritmos **baseados em distância**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando modelos')\n",
    "\n",
    "# Dividindo os dados em variáveis dependentes e independentes\n",
    "x = dados.drop(columns='prcnt_stock')\n",
    "y = dados.prcnt_stock\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x,\n",
    "                                                        y, test_size=0.25,\n",
    "                                                        random_state=14)\n",
    "\n",
    "# Instanciando os modelos\n",
    "linear_reg = LinearRegression()\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "elastic_nt = ElasticNet()\n",
    "reg_estocastico = SGDRegressor()\n",
    "\n",
    "# Criando listas com os modelos e tags\n",
    "modelos = [linear_reg, lasso, ridge, elastic_nt, reg_estocastico]\n",
    "tags = ['Reg_Linear', 'Lasso', 'Ridge', 'Elastic_Net', 'Reg_Estocástico']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T17:09:59.316033Z",
     "end_time": "2023-04-06T17:09:59.337705Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standard Scaler em todas as variáveis numéricas + One Hot Encoder em todas as categóricas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Instanciando os transformadores\n",
    "sc = StandardScaler()\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "# Selecionando os dados por tipo\n",
    "numericas = x_treino.select_dtypes(['int', 'float']).columns\n",
    "categoricas = x_treino.select_dtypes('object').columns\n",
    "\n",
    "# Criando o transformer\n",
    "transformer = ColumnTransformer(transformers=[('scaler', sc, numericas),\n",
    "                                              ('encoder', ohe, categoricas)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T17:39:16.145384Z",
     "end_time": "2023-04-06T17:39:16.156997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "pipe = Pipeline([('transformer', transformer),\n",
    "                 ('regressor', LinearRegression())])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T17:39:19.482387Z",
     "end_time": "2023-04-06T17:39:19.499083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 648, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[65], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpipe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                \u001B[49m\u001B[43mx_treino\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                \u001B[49m\u001B[43my_treino\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m    266\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[0;32m    267\u001B[0m     delayed(_fit_and_score)(\n\u001B[0;32m    268\u001B[0m         clone(estimator),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m cv\u001B[38;5;241m.\u001B[39msplit(X, y, groups)\n\u001B[0;32m    283\u001B[0m )\n\u001B[1;32m--> 285\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(scoring):\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    361\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    365\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    366\u001B[0m     )\n\u001B[1;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    370\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    372\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    376\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    377\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 648, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\Daniel\\OneDrive\\Documentos\\stock_level_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "cross_val_score(pipe,\n",
    "                x_treino,\n",
    "                y_treino,\n",
    "                cv=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
